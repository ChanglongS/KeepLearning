{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-03T01:17:30.640222Z",
     "start_time": "2024-12-03T01:17:30.637708Z"
    }
   },
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import jieba\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T01:22:33.251902Z",
     "start_time": "2024-12-03T01:22:33.247041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dict_vectorizer = DictVectorizer(sparse=True)\n",
    "data = dict_vectorizer.fit_transform([{'city': '北京', 'temperature': 100},\n",
    "                                      {'city': '上海', 'temperature': 80},\n",
    "                                      {'city': '广州', 'temperature': 60}])\n",
    "print(data)\n",
    "print(type(data))\n",
    "print(dict_vectorizer.get_feature_names_out())\n",
    "print(type(dict_vectorizer.inverse_transform(data)))\n",
    "print(dict_vectorizer.inverse_transform(data))\n",
    "print(data.toarray())"
   ],
   "id": "e6263c4d132134a6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 6 stored elements and shape (3, 4)>\n",
      "  Coords\tValues\n",
      "  (0, 1)\t1.0\n",
      "  (0, 3)\t100.0\n",
      "  (1, 0)\t1.0\n",
      "  (1, 3)\t80.0\n",
      "  (2, 2)\t1.0\n",
      "  (2, 3)\t60.0\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "['city=上海' 'city=北京' 'city=广州' 'temperature']\n",
      "<class 'list'>\n",
      "[{'city=北京': np.float64(1.0), 'temperature': np.float64(100.0)}, {'city=上海': np.float64(1.0), 'temperature': np.float64(80.0)}, {'city=广州': np.float64(1.0), 'temperature': np.float64(60.0)}]\n",
      "[[  0.   1.   0. 100.]\n",
      " [  1.   0.   0.  80.]\n",
      " [  0.   0.   1.  60.]]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T01:17:30.674519Z",
     "start_time": "2024-12-03T01:17:30.668173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "text_vectorizer = CountVectorizer(min_df=1)  # min_df默认为1\n",
    "text_data = text_vectorizer.fit_transform([\"life is  short,i like python life\",\n",
    "                                           \"life is too long,i dislike python\",\n",
    "                                           \"life is short\"])\n",
    "print(text_vectorizer.get_feature_names_out())\n",
    "print(text_data)\n",
    "print(type(text_data))\n",
    "print(text_data.toarray())\n",
    "print(text_vectorizer.inverse_transform(text_data))"
   ],
   "id": "2d3d6d3dde02d49a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dislike' 'is' 'life' 'like' 'long' 'python' 'short' 'too']\n",
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 14 stored elements and shape (3, 8)>\n",
      "  Coords\tValues\n",
      "  (0, 2)\t2\n",
      "  (0, 1)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 5)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 0)\t1\n",
      "  (2, 2)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 6)\t1\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "[[0 1 2 1 0 1 1 0]\n",
      " [1 1 1 0 1 1 0 1]\n",
      " [0 1 1 0 0 0 1 0]]\n",
      "[array(['life', 'is', 'short', 'like', 'python'], dtype='<U7'), array(['life', 'is', 'python', 'too', 'long', 'dislike'], dtype='<U7'), array(['life', 'is', 'short'], dtype='<U7')]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T01:17:30.703603Z",
     "start_time": "2024-12-03T01:17:30.700561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_vectorizer2 = CountVectorizer(min_df=1)\n",
    "text_data2 = text_vectorizer2.fit_transform([\"人生苦短，我 喜欢 python python\", \"人生漫长，不用 python\"])\n",
    "print(text_vectorizer2.get_feature_names_out())\n",
    "print(text_data2.toarray())\n",
    "print(text_data2)"
   ],
   "id": "f08021fb6d7fe777",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python' '不用' '人生漫长' '人生苦短' '喜欢']\n",
      "[[2 0 0 1 1]\n",
      " [1 1 1 0 0]]\n",
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 6 stored elements and shape (2, 5)>\n",
      "  Coords\tValues\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 0)\t2\n",
      "  (1, 0)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 1)\t1\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T01:17:31.029502Z",
     "start_time": "2024-12-03T01:17:30.717861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sen1 = jieba.cut(\"今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。\")\n",
    "sen2 = jieba.cut(\"我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。\")\n",
    "sen3 = jieba.cut(\n",
    "    \"如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。\")\n",
    "\n",
    "print(type(sen1))\n",
    "# print(sen1)\n",
    "s1 = list(sen1)\n",
    "print(s1)\n",
    "s2 = list(sen2)\n",
    "print(s2)\n",
    "s3 = list(sen3)\n",
    "print(s3)\n",
    "st1 = ' '.join(s1)\n",
    "st2 = ' '.join(s2)\n",
    "st3 = ' '.join(s3)\n",
    "print(st1)\n",
    "print(st2)\n",
    "print(st3)\n",
    "print('-' * 100)\n",
    "text_vectorizer3 = CountVectorizer()\n",
    "print(type(text_vectorizer3))\n",
    "data = text_vectorizer3.fit_transform([st1, st2, st3])\n",
    "print(text_vectorizer3.get_feature_names_out())\n",
    "print('-' * 100)\n",
    "print(type(data))\n",
    "print(data)\n",
    "print(data.toarray())\n"
   ],
   "id": "4e541184199a8266",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/lk/8ddg82lx22j4q109wghqhxlm0000gn/T/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.306 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['今天', '很', '残酷', '，', '明天', '更', '残酷', '，', '后天', '很', '美好', '，', '但', '绝对', '大部分', '是', '死', '在', '明天', '晚上', '，', '所以', '每个', '人', '不要', '放弃', '今天', '。']\n",
      "['我们', '看到', '的', '从', '很', '远', '星系', '来', '的', '光是在', '几百万年', '之前', '发出', '的', '，', '这样', '当', '我们', '看到', '宇宙', '时', '，', '我们', '是', '在', '看', '它', '的', '过去', '。']\n",
      "['如果', '只用', '一种', '方式', '了解', '某样', '事物', '，', '你', '就', '不会', '真正', '了解', '它', '。', '了解', '事物', '真正', '含义', '的', '秘密', '取决于', '如何', '将', '其', '与', '我们', '所', '了解', '的', '事物', '相', '联系', '。']\n",
      "今天 很 残酷 ， 明天 更 残酷 ， 后天 很 美好 ， 但 绝对 大部分 是 死 在 明天 晚上 ， 所以 每个 人 不要 放弃 今天 。\n",
      "我们 看到 的 从 很 远 星系 来 的 光是在 几百万年 之前 发出 的 ， 这样 当 我们 看到 宇宙 时 ， 我们 是 在 看 它 的 过去 。\n",
      "如果 只用 一种 方式 了解 某样 事物 ， 你 就 不会 真正 了解 它 。 了解 事物 真正 含义 的 秘密 取决于 如何 将 其 与 我们 所 了解 的 事物 相 联系 。\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<class 'sklearn.feature_extraction.text.CountVectorizer'>\n",
      "['一种' '不会' '不要' '之前' '了解' '事物' '今天' '光是在' '几百万年' '发出' '取决于' '只用' '后天' '含义'\n",
      " '大部分' '如何' '如果' '宇宙' '我们' '所以' '放弃' '方式' '明天' '星系' '晚上' '某样' '残酷' '每个'\n",
      " '看到' '真正' '秘密' '绝对' '美好' '联系' '过去' '这样']\n",
      "----------------------------------------------------------------------------------------------------\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 37 stored elements and shape (3, 36)>\n",
      "  Coords\tValues\n",
      "  (0, 6)\t2\n",
      "  (0, 26)\t2\n",
      "  (0, 22)\t2\n",
      "  (0, 12)\t1\n",
      "  (0, 32)\t1\n",
      "  (0, 31)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 24)\t1\n",
      "  (0, 19)\t1\n",
      "  (0, 27)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 20)\t1\n",
      "  (1, 18)\t3\n",
      "  (1, 28)\t2\n",
      "  (1, 23)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 35)\t1\n",
      "  (1, 17)\t1\n",
      "  (1, 34)\t1\n",
      "  (2, 18)\t1\n",
      "  (2, 16)\t1\n",
      "  (2, 11)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 21)\t1\n",
      "  (2, 4)\t4\n",
      "  (2, 25)\t1\n",
      "  (2, 5)\t3\n",
      "  (2, 1)\t1\n",
      "  (2, 29)\t2\n",
      "  (2, 13)\t1\n",
      "  (2, 30)\t1\n",
      "  (2, 10)\t1\n",
      "  (2, 15)\t1\n",
      "  (2, 33)\t1\n",
      "[[0 0 1 0 0 0 2 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 2 0 1 0 2 1 0 0 0 1 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 3 0 0 0 0 1 0 0 0 0 2 0 0 0 0 0 1 1]\n",
      " [1 1 0 0 4 3 0 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 2 1 0 0 1 0 0]]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T01:17:31.044552Z",
     "start_time": "2024-12-03T01:17:31.038886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "TV = TfidfVectorizer()\n",
    "data = TV.fit_transform([st1, st2, st3])\n",
    "print(TV.get_feature_names_out())\n",
    "print(data.toarray())"
   ],
   "id": "b9f1c6b76d46d9b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['一种' '不会' '不要' '之前' '了解' '事物' '今天' '光是在' '几百万年' '发出' '取决于' '只用' '后天' '含义'\n",
      " '大部分' '如何' '如果' '宇宙' '我们' '所以' '放弃' '方式' '明天' '星系' '晚上' '某样' '残酷' '每个'\n",
      " '看到' '真正' '秘密' '绝对' '美好' '联系' '过去' '这样']\n",
      "[[0.         0.         0.21821789 0.         0.         0.\n",
      "  0.43643578 0.         0.         0.         0.         0.\n",
      "  0.21821789 0.         0.21821789 0.         0.         0.\n",
      "  0.         0.21821789 0.21821789 0.         0.43643578 0.\n",
      "  0.21821789 0.         0.43643578 0.21821789 0.         0.\n",
      "  0.         0.21821789 0.21821789 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.2410822  0.         0.\n",
      "  0.         0.2410822  0.2410822  0.2410822  0.         0.\n",
      "  0.         0.         0.         0.         0.         0.2410822\n",
      "  0.55004769 0.         0.         0.         0.         0.2410822\n",
      "  0.         0.         0.         0.         0.48216441 0.\n",
      "  0.         0.         0.         0.         0.2410822  0.2410822 ]\n",
      " [0.15698297 0.15698297 0.         0.         0.62793188 0.47094891\n",
      "  0.         0.         0.         0.         0.15698297 0.15698297\n",
      "  0.         0.15698297 0.         0.15698297 0.15698297 0.\n",
      "  0.1193896  0.         0.         0.15698297 0.         0.\n",
      "  0.         0.15698297 0.         0.         0.         0.31396594\n",
      "  0.15698297 0.         0.         0.15698297 0.         0.        ]]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T01:17:31.058794Z",
     "start_time": "2024-12-03T01:17:31.055934Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mm = MinMaxScaler(feature_range=(0, 1))\n",
    "data = mm.fit_transform([[90, 2, 10, 40], [60, 4, 15, 45], [75, 3, 13, 46]])\n",
    "print(type(data))\n",
    "print(data)\n",
    "print('-' * 80)\n",
    "print(mm.get_feature_names_out())"
   ],
   "id": "8607339a676727d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[1.         0.         0.         0.        ]\n",
      " [0.         1.         1.         0.83333333]\n",
      " [0.5        0.5        0.6        1.        ]]\n",
      "--------------------------------------------------------------------------------\n",
      "['x0' 'x1' 'x2' 'x3']\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T01:17:31.072973Z",
     "start_time": "2024-12-03T01:17:31.069451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "data = standard_scaler.fit_transform([[90, 2, 10, 40],\n",
    "                                      [60, 4, 15, 45],\n",
    "                                      [75, 3, 13, 46]])\n",
    "print(data)\n",
    "print(standard_scaler.mean_)\n",
    "print(standard_scaler.var_)\n",
    "print('-' * 80)\n",
    "data2 = standard_scaler.fit_transform([[-1.06904497, -1.35873244, 0.98058068],\n",
    "                                       [-0.26726124, 0.33968311, 0.39223227],\n",
    "                                       [1.33630621, 1.01904933, -1.37281295]])\n",
    "print(standard_scaler.mean_)\n",
    "print(standard_scaler.var_)"
   ],
   "id": "b4b6aca89a6e1fab",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.22474487 -1.22474487 -1.29777137 -1.3970014 ]\n",
      " [-1.22474487  1.22474487  1.13554995  0.50800051]\n",
      " [ 0.          0.          0.16222142  0.88900089]]\n",
      "[75.          3.         12.66666667 43.66666667]\n",
      "[150.           0.66666667   4.22222222   6.88888889]\n",
      "--------------------------------------------------------------------------------\n",
      "[0. 0. 0.]\n",
      "[1.         1.         1.00000001]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 缺失值处理",
   "id": "192baaf485aecd39"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T01:17:31.319462Z",
     "start_time": "2024-12-03T01:17:31.083221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "impute = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "data_impute = impute.fit_transform([[1, 2], [np.nan, 3], [7, 6], [3, 2]])\n",
    "print(data_impute)"
   ],
   "id": "1847783f2f74d6d5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         2.        ]\n",
      " [3.66666667 3.        ]\n",
      " [7.         6.        ]\n",
      " [3.         2.        ]]\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 方差阀值",
   "id": "627b2e39a32a98f9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T01:17:31.335652Z",
     "start_time": "2024-12-03T01:17:31.328332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "variance = VarianceThreshold(threshold=0)\n",
    "data_variance = variance.fit_transform([[0, 2, 0, 3],\n",
    "                                        [0, 1, 4, 3],\n",
    "                                        [0, 1, 1, 3]])\n",
    "print(data_variance)\n",
    "print('the support is %s' % variance.get_support(True))"
   ],
   "id": "ad23b47b67906172",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0]\n",
      " [1 4]\n",
      " [1 1]]\n",
      "the support is [1 2]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 降维",
   "id": "51fd15c747a6e14f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T01:17:31.361136Z",
     "start_time": "2024-12-03T01:17:31.349237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "data_pca = pca.fit_transform([[2, 8, 4, 5],\n",
    "                   [6, 3, 0, 8],\n",
    "                   [5, 4, 9, 1]])\n",
    "print(data_pca)"
   ],
   "id": "c2c22d8169cf3704",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-9.33473422e-16  3.82970843e+00]\n",
      " [-5.74456265e+00 -1.91485422e+00]\n",
      " [ 5.74456265e+00 -1.91485422e+00]]\n"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
